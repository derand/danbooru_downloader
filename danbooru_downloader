#!/usr/bin/env python
# -*- coding: utf-8 -*-

__version__ = '0.1'
__author__ = 'Andrey Derevyagin'
__maintainer__ = 'Andrey Derevyagin'
__email__ = '2derand+downloader@gmail.com'
__copyright__ = 'Copyright Â© 2012, Andrey Derevyagin'
__license__ = 'Use this code as you want'


import requests
import re
import sys, os
import argparse


re_sub_domain = re.compile('http://.+\.sankaku')


class Danbooru(object):
	"""docstring for Danbooru"""
	def __init__(self, domain, query):
		super(Danbooru, self).__init__()
		self.__domain = domain
		self.query = query
		self.__path = path
		self.page = 1
		self.page_size = 25

	def posts(self, inc_page=True):
		'''
			Posts from one page
		'''
		args = 'page=%d&limit=%d'%(self.page, self.page)
		if inc_page:
			self.page += 1
		if len(self.query):
			args += '&tags=%s'%self.query
		req = requests.get('%s/post/index.json?%s'%(self.__domain, args))
		return req.json

	def full_size_url(self, post):
		'''
			return url and raw iamge
		'''
		if post.has_key('file_url'):
			url = post['file_url']
			return (url, requests.get(url).content)
		if post.has_key('jpeg_url'):
			url = post['jpeg_url']
			return (url, requests.get(url).content)

		# build & search full-sized url for sanakakucomplex
		if self.__domain.find('sankaku')>-1:
			thumnail_url = post['preview_url']
			t_url = thumnail_url.replace('/preview/', '/')
			sub_domain = self.__domain[self.__domain.find('://')+3]
			if sub_domain=='i':
				sub_domains = ['idol', 'i1', 'i2', 'i3', 'i4']
			else:
				sub_domains = ['chan', 'c1', 'c2', 'c3', 'c4']
			for sub_domain in sub_domains:
				for ext in ['.jpg', '.png', '.gif']:
					url = re_sub_domain.sub('http://%s.sankaku'%sub_domain, t_url)[:-4]+ext
					responce = requests.get(url)
					if responce.status_code==200:
						return (url, responce.content)
		return ('', None)


if __name__=='__main__':
	# http://chan.sankakucomplex.com/post/index.json?limit=10&page=2&tags=vocaloid
	parser = argparse.ArgumentParser(
		description='Downloader from imageboards with danbooru engine.',
		epilog='')
	parser.add_argument('-q', '--query', help='search tags (standart danbooru format)', type=str, default='')
	parser.add_argument('-p', '--path', help='store path', type=str, default='imgs')
	parser.add_argument('-c', '--count', help='image count', type=int, default=5)
	parser.add_argument('-d', '--domain', help='danbooru board domain (default: http://chan.sankakucomplex.com)',
						 default='http://chan.sankakucomplex.com')

	args = vars(parser.parse_args())

	count = args['count']
	path = args['path']
	if not os.path.exists(path):
		os.mkdir(path)

	danbooru = Danbooru(args['domain'], args['query'])
	i = 0
	posts = danbooru.posts()
	if len(posts)>0:
		while i<count or count==-1:
			post = posts[0]
			(url, content) = danbooru.full_size_url(post)
			del posts[0]
			if len(url) and content!=None:
				print '[%d] %s => %s'%(i+1,post['preview_url'], url)
				f = open('%s/%s.%s'%(path, post['md5'], url[-3:]), 'wb')
				f.write(content)
				f.close()
				i += 1
			if len(posts)==0:
				posts = danbooru.posts()
				if len(posts)==0:
					break

