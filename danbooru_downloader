#!/usr/bin/env python
# -*- coding: utf-8 -*-

__version__ = '0.1'
__author__ = 'Andrey Derevyagin'
__maintainer__ = 'Andrey Derevyagin'
__email__ = '2derand+downloader@gmail.com'
__copyright__ = 'Copyright Â© 2012, Andrey Derevyagin'
__license__ = 'Use this code us you want'


import requests
import re
import sys, os
import argparse


re_sub_domain = re.compile('http://.+\.sankaku')


class Danbooru(object):
	"""docstring for Danbooru"""
	def __init__(self, domain, query):
		super(Danbooru, self).__init__()
		self.__domain = domain
		self.query = query
		self.__path = path
		self.page = 1
		self.page_size = 25

	def posts(self, inc_page=True):
		'''
			Posts from one page
		'''
		args = 'page=%d&limit=%d'%(self.page, self.page)
		if inc_page:
			self.page += 1
		if len(self.query):
			args += '&tags=%s'%self.query
		req = requests.get('%s/post/index.json?%s'%(self.__domain, args))
		return req.json

	def full_size_url(self, post):
		'''
			return url and raw iamge
		'''
		if post.has_key('file_url') and self.check_url(post['file_url']):
			url = post['file_url']
			return (url, requests.get(url).content)

		# build & search fill-sized url for sanakakucomplex
		thumnail_url = post['preview_url']
		t_url = thumnail_url.replace('/preview/', '/')
		for sub_domain in ['chan', 'c1', 'c2', 'c3', 'c4']:
			for ext in ['.jpg', '.png', '.gif']:
				url = re_sub_domain.sub('http://%s.sankaku'%sub_domain, t_url)[:-4]+ext
				responce = requests.get(url)
				if responce.status_code==200:
					return (url, responce.content)
		return ('', None)


if __name__=='__main__':
	# http://chan.sankakucomplex.com/post/index.json?limit=10&page=2&tags=vocaloid
	parser = argparse.ArgumentParser(
		description='Downloader from imageboards with danbooru engine.',
		epilog='')
	parser.add_argument('-q', '--query', help='search tags (standart danbooru format)', type=str, default='')
	parser.add_argument('-d', '-p', '--path', help='store path', type=str, default='imgs')
	parser.add_argument('-c', '--count', help='image count', type=int, default=5)

	args = vars(parser.parse_args())
	args['domain'] = 'http://chan.sankakucomplex.com'

	count = args['count']
	path = args['path']
	if not os.path.exists(path):
		os.mkdir(path)

	sankaku = Danbooru(args['domain'], args['query'])
	i = 0
	posts = sankaku.posts()
	while i<count:
		post = posts[0]
		(url, content) = sankaku.full_size_url(post)
		del posts[0]
		if len(url) and content!=None:
			print "%s => %s"%(post['preview_url'], url)
			f = open('%s/%s.%s'%(path, post['md5'], url[-3:]), 'wb')
			f.write(content)
			f.close()
			i += 1
		if len(posts)==0:
			posts = sankaku.posts()
			if len(posts)==0:
				break

